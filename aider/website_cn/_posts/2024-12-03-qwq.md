---
title: QwQ是代码架构师，而非编辑器
excerpt: QwQ是类似o1的推理模型，需要作为架构师与另一个模型作为编辑器一起使用。
highlight_image: /assets/qwq.jpg
draft: false
nav_exclude: true
---
{% if page.date %}
<p class="post-date">{{ page.date | date: "%B %d, %Y" }}</p>
{% endif %}

# QwQ是代码架构师，而非编辑器
{: .no_toc }

<canvas id="qwqChart" width="800" height="500" style="margin: 20px 0"></canvas>

QwQ 32B Preview是一个"推理"模型，在呈现最终响应之前会花费大量标记进行思考。
这类似于OpenAI的o1模型，在aider中[当与传统LLM配对作为架构师和编辑器时](https://aider.chat/2024/09/26/architect.html)最为有效。
在这种模式下，推理模型充当"架构师"，提出解决编码问题的方案，而不考虑如何实际编辑源文件。
"编辑器"模型接收该提案，并专注于如何编辑现有源代码来实现它。

单独使用而不与编辑器配对时，
QwQ甚至无法遵循最简单的[编辑格式](https://aider.chat/docs/more/edit-formats.html)。
它无法可靠地编辑源代码文件。
因此，QwQ在基准测试中的单独得分相当令人失望
（远远差于单独执行的o1模型）。

QwQ基于Qwen 2.5 Coder 32B Instruct，
当与其配对作为架构师+编辑器组合时表现更好。
尽管这只比单独使用Qwen提供了适度的基准改进，
而且在延迟方面成本相当高。
每个请求都必须等待QwQ返回所有思考文本
和最终解决方案提案。
然后必须等待Qwen将该大型响应转换为实际文件编辑。

将QwQ与其他合理的编辑器模型配对的表现与
单独使用Qwen 2.5 Coder 32B Instruct相同或更差。

QwQ+Qwen似乎是使用QwQ的最佳方式，达到了74%的分数。
这远低于该基准测试的SOTA结果：Sonnet单独得分为84%，
而o1-preview + o1-mini作为架构师+编辑器得分为85%。


## QwQ特定的编辑格式

我花了一些时间尝试各种为QwQ定制的编辑格式。
特别是，我尝试解析QwQ响应并丢弃长篇的"思考"部分，
只保留"最终"解决方案。
这些定制工作似乎都没有转化为
基准测试结果的任何显著改进。


## 结果

<script src="https://cdn.jsdelivr.net/npm/chart.js"></script>
<script>
{% include qwq-chart.js %}
</script>

<table style="width: 100%; max-width: 800px; margin: auto; border-collapse: collapse; box-shadow: 0 2px 4px rgba(0,0,0,0.1); font-size: 14px;">
  <thead style="background-color: #f2f2f2;">
    <tr>
      <th style="padding: 8px; text-align: left;">模型</th>
      <th style="padding: 8px; text-align: center;">正确完成百分比</th>
      <th style="padding: 8px; text-align: center;">使用正确编辑格式的百分比</th>
      <th style="padding: 8px; text-align: left;">命令</th>
      <th style="padding: 8px; text-align: center;">编辑格式</th>
    </tr>
  </thead>
  <tbody>
    {% assign qwq_sorted = site.data.qwq | sort: 'pass_rate_2' | reverse %}
    {% for row in qwq_sorted %}
      <tr style="border-bottom: 1px solid #ddd;">
        <td style="padding: 8px;">{{ row.model }}</td>
        <td style="padding: 8px; text-align: center;">{{ row.pass_rate_2 }}%</td>
        <td style="padding: 8px; text-align: center;">{{ row.percent_cases_well_formed }}%</td>
        <td style="padding: 8px;"><code>{{ row.command }}</code></td>
        <td style="padding: 8px; text-align: center;">{{ row.edit_format }}</td>
      </tr>
    {% endfor %}
  </tbody>
</table>

<style>
  tr.selected {
    color: #0056b3;
  }
  table {
    table-layout: fixed;
  }
  td, th {
    word-wrap: break-word;
    overflow-wrap: break-word;
  }
  td:nth-child(3), td:nth-child(4) {
    font-size: 12px;
  }
</style>

<script>
document.getElementById('qwqSearchInput').addEventListener('keyup', function() {
    var input = this.value.toLowerCase();
    var rows = document.querySelectorAll('tbody tr');
    
    rows.forEach(function(row) {
        var text = row.textContent.toLowerCase();
        if(text.includes(input)) {
            row.style.display = '';
            row.classList.add('selected');
        } else {
            row.style.display = 'none';
            row.classList.remove('selected');
        }
    });
});
</script>

## 开源模型注意事项

正如最近的博客文章中讨论的，
[开源模型的细节很重要](https://aider.chat/2024/11/21/quantization.html)。
为了清晰起见，本文的新基准测试运行是
针对OpenRouter的QwQ 32B Preview和Qwen 2.5 Coder 32B Instruct端点进行的。
对于其他模型，基准测试直接使用它们提供商的API。

最近对OpenRouter的Qwen 2.5 Coder 32B Instruct端点进行了广泛测试，
它似乎是可靠的。
提供商Mancer因其提供的上下文窗口小而被阻止。

对于QwQ 32B Preview，Fireworks因其上下文窗口小而被阻止。
